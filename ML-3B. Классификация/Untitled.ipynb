{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4538fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # функция, чтобы разбить данные на трейн и тест\n",
    "from sklearn.linear_model import LogisticRegression # наша модель для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4608c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris # подгружаем датасет\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e1cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = iris.target ## Наша целевая переменная, 0 — если рака нет, 1 — если есть \n",
    "X = iris.data # X - признаки, по которым мы будем предсказывать рак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5b1fa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.5)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c137078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m Y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(Y_val,Y_predicted))\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_predicted\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(recall_score(Y_val,Y_predicted))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(f1_score(Y_val,Y_predicted))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[0;32m   1629\u001b[0m     y_true,\n\u001b[0;32m   1630\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1637\u001b[0m ):\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1365\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1364\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1366\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1368\u001b[0m         )\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1370\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1376\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "Y_predicted = model.predict(X_val)\n",
    "print(accuracy_score(Y_val,Y_predicted))\n",
    "print(precision_score(Y_val,Y_predicted))\n",
    "print(recall_score(Y_val,Y_predicted))\n",
    "print(f1_score(Y_val,Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3200da",
   "metadata": {},
   "source": [
    "### Задание 3B.2.1\n",
    "\n",
    "### Вы создали классификатор, который разделяет экономические и политические новости на два разных Telegram-канала, и хотите проверить его качество. За день вышло 15 политических новостей и 20 экономических. Ваш алгоритм из 15 политических новостей отметил 9 как экономические, а из 20 экономических — 6 как политические. Найдите метрику $Accuracy$.\n",
    "### Ответы:0,57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963c2f7",
   "metadata": {},
   "source": [
    "### Задание 3B2.2\n",
    "\n",
    "### Загрузите встроенный в библиотеку *sklearn* датасет про ирисы с помощью функции `load_iris`. Обучите модель логистической регрессии (`random_state=50`, размер тестовой выборки `0.3`) и укажите полученное значение метрики $Accuracy$.\n",
    "### Ответ:0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "408a03be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            0  \n",
       "1        1             1     0            1  \n",
       "2        1             1     0            1  \n",
       "3        1             0     0            1  \n",
       "4        1             1     0            0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('train_mobile.csv',sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a1a13e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2  ...         20       756  2549     9     7   \n",
       "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
       "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
       "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            0  \n",
       "1             7        1             1     0            1  \n",
       "2             9        1             1     0            1  \n",
       "3            11        1             0     0            1  \n",
       "4            15        1             1     0            0  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            1  \n",
       "1997          5        1             1     0            1  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            1  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e374b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>battery_power</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>-0.041847</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.034085</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.029727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>-0.008402</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-0.029959</td>\n",
       "      <td>-0.021421</td>\n",
       "      <td>0.052510</td>\n",
       "      <td>0.011522</td>\n",
       "      <td>-0.010516</td>\n",
       "      <td>-0.008343</td>\n",
       "      <td>0.149402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.011252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>-0.008605</td>\n",
       "      <td>0.036161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>-0.041533</td>\n",
       "      <td>0.026351</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>-0.030236</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>-0.021863</td>\n",
       "      <td>0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clock_speed</th>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>-0.014364</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>-0.005724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014523</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>-0.029078</td>\n",
       "      <td>-0.007378</td>\n",
       "      <td>-0.011432</td>\n",
       "      <td>-0.046433</td>\n",
       "      <td>0.019756</td>\n",
       "      <td>-0.024471</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dual_sim</th>\n",
       "      <td>-0.041847</td>\n",
       "      <td>0.035198</td>\n",
       "      <td>-0.001315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029123</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>-0.024658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020875</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>-0.011949</td>\n",
       "      <td>-0.016666</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-0.014008</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.009002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc</th>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>-0.029123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016560</td>\n",
       "      <td>-0.029133</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0.023618</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009990</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>-0.012373</td>\n",
       "      <td>-0.006829</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>0.022464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_g</th>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>-0.043073</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>-0.016560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.029706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>-0.046628</td>\n",
       "      <td>0.584246</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>0.001001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_memory</th>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.029133</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>-0.034214</td>\n",
       "      <td>-0.028310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>-0.008335</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>-0.002790</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>-0.026999</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.022132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_dep</th>\n",
       "      <td>0.034085</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>-0.014364</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-0.025348</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>-0.028353</td>\n",
       "      <td>-0.018554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_wt</th>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.008605</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>0.023618</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.034214</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>-0.033855</td>\n",
       "      <td>-0.020761</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_cores</th>\n",
       "      <td>-0.029727</td>\n",
       "      <td>0.036161</td>\n",
       "      <td>-0.005724</td>\n",
       "      <td>-0.024658</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>-0.029706</td>\n",
       "      <td>-0.028310</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>0.031260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>0.031441</td>\n",
       "      <td>-0.009952</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>0.644595</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>-0.033273</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018465</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>-0.023819</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>-0.008742</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.027628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_height</th>\n",
       "      <td>0.014901</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>-0.014523</td>\n",
       "      <td>-0.020875</td>\n",
       "      <td>-0.009990</td>\n",
       "      <td>-0.019236</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>-0.020352</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>-0.010645</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>0.097951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>px_width</th>\n",
       "      <td>-0.008402</td>\n",
       "      <td>-0.041533</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>-0.005176</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>-0.008335</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.116703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram</th>\n",
       "      <td>-0.000653</td>\n",
       "      <td>0.026351</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>-0.009434</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020352</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.822354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_h</th>\n",
       "      <td>-0.029959</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>-0.029078</td>\n",
       "      <td>-0.011949</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>-0.025348</td>\n",
       "      <td>-0.033855</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>-0.017335</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.009140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_w</th>\n",
       "      <td>-0.021421</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>-0.007378</td>\n",
       "      <td>-0.016666</td>\n",
       "      <td>-0.012373</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>-0.018388</td>\n",
       "      <td>-0.020761</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.506144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022821</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.035423</td>\n",
       "      <td>0.035359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk_time</th>\n",
       "      <td>0.052510</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>-0.011432</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-0.006829</td>\n",
       "      <td>-0.046628</td>\n",
       "      <td>-0.002790</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010645</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>-0.017335</td>\n",
       "      <td>-0.022821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042688</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>-0.029504</td>\n",
       "      <td>0.004394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three_g</th>\n",
       "      <td>0.011522</td>\n",
       "      <td>-0.030236</td>\n",
       "      <td>-0.046433</td>\n",
       "      <td>-0.014008</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.584246</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>-0.012065</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>0.030941</td>\n",
       "      <td>-0.042688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.024638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>touch_screen</th>\n",
       "      <td>-0.010516</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.019756</td>\n",
       "      <td>-0.017117</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>-0.026999</td>\n",
       "      <td>-0.002638</td>\n",
       "      <td>-0.014368</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>-0.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wifi</th>\n",
       "      <td>-0.008343</td>\n",
       "      <td>-0.021863</td>\n",
       "      <td>-0.024471</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>-0.028353</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.035423</td>\n",
       "      <td>-0.029504</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_range</th>\n",
       "      <td>0.149402</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.022464</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>-0.018554</td>\n",
       "      <td>-0.007968</td>\n",
       "      <td>0.031260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097951</td>\n",
       "      <td>0.116703</td>\n",
       "      <td>0.822354</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>-0.040001</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               battery_power      blue  clock_speed  dual_sim        fc  \\\n",
       "battery_power       1.000000  0.011252     0.011482 -0.041847  0.033334   \n",
       "blue                0.011252  1.000000     0.021419  0.035198  0.003593   \n",
       "clock_speed         0.011482  0.021419     1.000000 -0.001315 -0.000434   \n",
       "dual_sim           -0.041847  0.035198    -0.001315  1.000000 -0.029123   \n",
       "fc                  0.033334  0.003593    -0.000434 -0.029123  1.000000   \n",
       "four_g              0.015665  0.013443    -0.043073  0.003187 -0.016560   \n",
       "int_memory         -0.004004  0.041177     0.006545 -0.015679 -0.029133   \n",
       "m_dep               0.034085  0.004049    -0.014364 -0.022142 -0.001791   \n",
       "mobile_wt           0.001844 -0.008605     0.012350 -0.008979  0.023618   \n",
       "n_cores            -0.029727  0.036161    -0.005724 -0.024658 -0.013356   \n",
       "pc                  0.031441 -0.009952    -0.005245 -0.017143  0.644595   \n",
       "px_height           0.014901 -0.006872    -0.014523 -0.020875 -0.009990   \n",
       "px_width           -0.008402 -0.041533    -0.009476  0.014291 -0.005176   \n",
       "ram                -0.000653  0.026351     0.003443  0.041072  0.015099   \n",
       "sc_h               -0.029959 -0.002952    -0.029078 -0.011949 -0.011014   \n",
       "sc_w               -0.021421  0.000613    -0.007378 -0.016666 -0.012373   \n",
       "talk_time           0.052510  0.013934    -0.011432 -0.039404 -0.006829   \n",
       "three_g             0.011522 -0.030236    -0.046433 -0.014008  0.001793   \n",
       "touch_screen       -0.010516  0.010061     0.019756 -0.017117 -0.014828   \n",
       "wifi               -0.008343 -0.021863    -0.024471  0.022740  0.020085   \n",
       "price_range         0.149402  0.014001     0.003494  0.009002  0.022464   \n",
       "\n",
       "                 four_g  int_memory     m_dep  mobile_wt   n_cores  ...  \\\n",
       "battery_power  0.015665   -0.004004  0.034085   0.001844 -0.029727  ...   \n",
       "blue           0.013443    0.041177  0.004049  -0.008605  0.036161  ...   \n",
       "clock_speed   -0.043073    0.006545 -0.014364   0.012350 -0.005724  ...   \n",
       "dual_sim       0.003187   -0.015679 -0.022142  -0.008979 -0.024658  ...   \n",
       "fc            -0.016560   -0.029133 -0.001791   0.023618 -0.013356  ...   \n",
       "four_g         1.000000    0.008690 -0.001823  -0.016537 -0.029706  ...   \n",
       "int_memory     0.008690    1.000000  0.006886  -0.034214 -0.028310  ...   \n",
       "m_dep         -0.001823    0.006886  1.000000   0.021756 -0.003504  ...   \n",
       "mobile_wt     -0.016537   -0.034214  0.021756   1.000000 -0.018989  ...   \n",
       "n_cores       -0.029706   -0.028310 -0.003504  -0.018989  1.000000  ...   \n",
       "pc            -0.005598   -0.033273  0.026282   0.018844 -0.001193  ...   \n",
       "px_height     -0.019236    0.010441  0.025263   0.000939 -0.006872  ...   \n",
       "px_width       0.007448   -0.008335  0.023566   0.000090  0.024480  ...   \n",
       "ram            0.007313    0.032813 -0.009434  -0.002581  0.004868  ...   \n",
       "sc_h           0.027166    0.037771 -0.025348  -0.033855 -0.000315  ...   \n",
       "sc_w           0.037005    0.011731 -0.018388  -0.020761  0.025826  ...   \n",
       "talk_time     -0.046628   -0.002790  0.017003   0.006209  0.013148  ...   \n",
       "three_g        0.584246   -0.009366 -0.012065   0.001551 -0.014733  ...   \n",
       "touch_screen   0.016758   -0.026999 -0.002638  -0.014368  0.023774  ...   \n",
       "wifi          -0.017620    0.006993 -0.028353  -0.000409 -0.009964  ...   \n",
       "price_range    0.001001    0.022132 -0.018554  -0.007968  0.031260  ...   \n",
       "\n",
       "               px_height  px_width       ram      sc_h      sc_w  talk_time  \\\n",
       "battery_power   0.014901 -0.008402 -0.000653 -0.029959 -0.021421   0.052510   \n",
       "blue           -0.006872 -0.041533  0.026351 -0.002952  0.000613   0.013934   \n",
       "clock_speed    -0.014523 -0.009476  0.003443 -0.029078 -0.007378  -0.011432   \n",
       "dual_sim       -0.020875  0.014291  0.041072 -0.011949 -0.016666  -0.039404   \n",
       "fc             -0.009990 -0.005176  0.015099 -0.011014 -0.012373  -0.006829   \n",
       "four_g         -0.019236  0.007448  0.007313  0.027166  0.037005  -0.046628   \n",
       "int_memory      0.010441 -0.008335  0.032813  0.037771  0.011731  -0.002790   \n",
       "m_dep           0.025263  0.023566 -0.009434 -0.025348 -0.018388   0.017003   \n",
       "mobile_wt       0.000939  0.000090 -0.002581 -0.033855 -0.020761   0.006209   \n",
       "n_cores        -0.006872  0.024480  0.004868 -0.000315  0.025826   0.013148   \n",
       "pc             -0.018465  0.004196  0.028984  0.004938 -0.023819   0.014657   \n",
       "px_height       1.000000  0.510664 -0.020352  0.059615  0.043038  -0.010645   \n",
       "px_width        0.510664  1.000000  0.004105  0.021599  0.034699   0.006720   \n",
       "ram            -0.020352  0.004105  1.000000  0.015996  0.035576   0.010820   \n",
       "sc_h            0.059615  0.021599  0.015996  1.000000  0.506144  -0.017335   \n",
       "sc_w            0.043038  0.034699  0.035576  0.506144  1.000000  -0.022821   \n",
       "talk_time      -0.010645  0.006720  0.010820 -0.017335 -0.022821   1.000000   \n",
       "three_g        -0.031174  0.000350  0.015795  0.012033  0.030941  -0.042688   \n",
       "touch_screen    0.021891 -0.001628 -0.030455 -0.020023  0.012720   0.017196   \n",
       "wifi            0.051824  0.030319  0.022669  0.025929  0.035423  -0.029504   \n",
       "price_range     0.097951  0.116703  0.822354  0.009140  0.035359   0.004394   \n",
       "\n",
       "                three_g  touch_screen      wifi  price_range  \n",
       "battery_power  0.011522     -0.010516 -0.008343     0.149402  \n",
       "blue          -0.030236      0.010061 -0.021863     0.014001  \n",
       "clock_speed   -0.046433      0.019756 -0.024471     0.003494  \n",
       "dual_sim      -0.014008     -0.017117  0.022740     0.009002  \n",
       "fc             0.001793     -0.014828  0.020085     0.022464  \n",
       "four_g         0.584246      0.016758 -0.017620     0.001001  \n",
       "int_memory    -0.009366     -0.026999  0.006993     0.022132  \n",
       "m_dep         -0.012065     -0.002638 -0.028353    -0.018554  \n",
       "mobile_wt      0.001551     -0.014368 -0.000409    -0.007968  \n",
       "n_cores       -0.014733      0.023774 -0.009964     0.031260  \n",
       "pc            -0.001322     -0.008742  0.005389     0.027628  \n",
       "px_height     -0.031174      0.021891  0.051824     0.097951  \n",
       "px_width       0.000350     -0.001628  0.030319     0.116703  \n",
       "ram            0.015795     -0.030455  0.022669     0.822354  \n",
       "sc_h           0.012033     -0.020023  0.025929     0.009140  \n",
       "sc_w           0.030941      0.012720  0.035423     0.035359  \n",
       "talk_time     -0.042688      0.017196 -0.029504     0.004394  \n",
       "three_g        1.000000      0.013917  0.004316     0.024638  \n",
       "touch_screen   0.013917      1.000000  0.011917    -0.040001  \n",
       "wifi           0.004316      0.011917  1.000000     0.014001  \n",
       "price_range    0.024638     -0.040001  0.014001     1.000000  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5df279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aecbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'Not Available': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "099460c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Histogram of the Energy Star Score\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.hist(data['battery_power'].dropna(), bins = 100, edgecolor = 'k');\n",
    "plt.xlabel('battery_power'); plt.ylabel('px_height');\n",
    "plt.title('fc');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a99fa9",
   "metadata": {},
   "source": [
    "### Задание 3B.3.2 Выбор метрики\n",
    "\n",
    "### Что это за метрика?\n",
    "### Ответ:precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4888d45",
   "metadata": {},
   "source": [
    "### Задание 3B.3.1 Отбор признаков\n",
    "### Ответ:battery_power,px_height, px_width,touch_screen\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923b3dc",
   "metadata": {},
   "source": [
    "### Задание 3B.4.1\n",
    "\n",
    "### Зачем вводится понятие *margin*?\n",
    "### Ответы:- [ ]  Чтобы свести классификацию к регрессии\n",
    "###  Чтобы сделать функцию потерь непрерывной\n",
    "### Чтобы точнее оценивать качество модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca8fe1",
   "metadata": {},
   "source": [
    "### Задание 3B.4.2\n",
    "\n",
    "### Какие из этих выборок линейно разделимы?\n",
    " ### Овет: Левая линейно разделимая"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c54656",
   "metadata": {},
   "source": [
    "### Задание 3B.4.3\n",
    "\n",
    "### Почему линейная регрессия плохо подходит для предсказания вероятности?\n",
    "### Ответ: Линейная регрессия может предсказать значения меньше 0 или больше 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c887f0",
   "metadata": {},
   "source": [
    "### Задание 3B.5.1\n",
    "\n",
    "### У какой из этих логистических функций больше коэффициент , а у какой — ?\n",
    "###  Ответ: У первой функции значение $k$ и $P$ больше, чем у второй"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2cd95",
   "metadata": {},
   "source": [
    "### Задание 3B.5.2\n",
    "\n",
    "### Почему $logloss$  больше подходит для оценки качества логистической регрессии, чем $accuracy$?\n",
    "### Ответ: $logloss $ учитывает уверенность классификатора в ответе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c26cff",
   "metadata": {},
   "source": [
    "### Задание 3B.5.3\n",
    "\n",
    "### Посчитайте  $logloss$  для данных в таблице (без нормализации). Укажите число с точностью до сотых:\n",
    "### Ответ: 2.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e3740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b882db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb0bcd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mX\u001b[49m, theta) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m      2\u001b[0m print_logisitc_metrics(y, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb486d26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      2\u001b[0m theta \u001b[38;5;241m=\u001b[39m optimize(X_train, y_train, calc_binary_cross_entropy_grad, np\u001b[38;5;241m.\u001b[39mones(m), \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m sigmoid(X_valid, theta) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
    "y_pred = sigmoid(X_valid, theta) > 0.5\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5895457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
